Running simulation
batch: 2
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:09<00:19,  9.53s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:18<00:09,  9.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:24<00:00,  7.76s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:24<00:00,  8.20s/it]
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 921.83 examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 916.32 examples/s]
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2282.22 examples/s]
  0%|          | 0/24 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  4%|▍         | 1/24 [00:22<08:45, 22.85s/it]  8%|▊         | 2/24 [00:48<08:56, 24.37s/it] 12%|█▎        | 3/24 [01:09<08:00, 22.87s/it] 17%|█▋        | 4/24 [01:30<07:21, 22.09s/it] 21%|██        | 5/24 [01:55<07:18, 23.07s/it]
  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:28,  3.46it/s][A
  3%|▎         | 3/100 [00:00<00:32,  2.99it/s][A
  4%|▍         | 4/100 [00:01<00:37,  2.54it/s][A
  5%|▌         | 5/100 [00:01<00:38,  2.50it/s][A
  6%|▌         | 6/100 [00:02<00:40,  2.34it/s][A
  7%|▋         | 7/100 [00:02<00:43,  2.14it/s][A
  8%|▊         | 8/100 [00:03<00:44,  2.09it/s][A
  9%|▉         | 9/100 [00:03<00:43,  2.11it/s][A
 10%|█         | 10/100 [00:04<00:45,  1.97it/s][A
 11%|█         | 11/100 [00:05<00:47,  1.86it/s][A
 12%|█▏        | 12/100 [00:05<00:43,  2.01it/s][A
 13%|█▎        | 13/100 [00:05<00:39,  2.21it/s][A
 14%|█▍        | 14/100 [00:06<00:35,  2.44it/s][A
 15%|█▌        | 15/100 [00:06<00:31,  2.71it/s][A
 16%|█▌        | 16/100 [00:06<00:31,  2.65it/s][A
 17%|█▋        | 17/100 [00:07<00:33,  2.51it/s][A
 18%|█▊        | 18/100 [00:07<00:33,  2.43it/s][A
 19%|█▉        | 19/100 [00:08<00:31,  2.56it/s][A
 20%|██        | 20/100 [00:08<00:32,  2.48it/s][A
 21%|██        | 21/100 [00:08<00:29,  2.68it/s][A
 22%|██▏       | 22/100 [00:09<00:30,  2.60it/s][A
 23%|██▎       | 23/100 [00:09<00:32,  2.39it/s][A
 24%|██▍       | 24/100 [00:10<00:35,  2.12it/s][A
 25%|██▌       | 25/100 [00:10<00:38,  1.94it/s][A
 26%|██▌       | 26/100 [00:11<00:38,  1.92it/s][A
 27%|██▋       | 27/100 [00:11<00:35,  2.06it/s][A
 28%|██▊       | 28/100 [00:12<00:30,  2.35it/s][A
 29%|██▉       | 29/100 [00:12<00:31,  2.26it/s][A
 30%|███       | 30/100 [00:12<00:29,  2.35it/s][A
 31%|███       | 31/100 [00:13<00:30,  2.24it/s][A
 32%|███▏      | 32/100 [00:14<00:33,  2.03it/s][A
 33%|███▎      | 33/100 [00:14<00:31,  2.15it/s][A
 34%|███▍      | 34/100 [00:15<00:32,  2.03it/s][A
 35%|███▌      | 35/100 [00:15<00:34,  1.88it/s][A
 36%|███▌      | 36/100 [00:16<00:35,  1.79it/s][A
 37%|███▋      | 37/100 [00:16<00:36,  1.73it/s][A
 38%|███▊      | 38/100 [00:17<00:36,  1.71it/s][A
 39%|███▉      | 39/100 [00:18<00:36,  1.68it/s][A
 40%|████      | 40/100 [00:18<00:33,  1.77it/s][A
 41%|████      | 41/100 [00:18<00:29,  1.97it/s][A
 42%|████▏     | 42/100 [00:19<00:26,  2.16it/s][A
 43%|████▎     | 43/100 [00:19<00:23,  2.44it/s][A
 44%|████▍     | 44/100 [00:20<00:25,  2.24it/s][A
 45%|████▌     | 45/100 [00:20<00:24,  2.26it/s][A
 46%|████▌     | 46/100 [00:21<00:24,  2.23it/s][A
 47%|████▋     | 47/100 [00:21<00:26,  2.04it/s][A
 48%|████▊     | 48/100 [00:22<00:26,  1.98it/s][A
 49%|████▉     | 49/100 [00:22<00:22,  2.22it/s][A
 50%|█████     | 50/100 [00:22<00:20,  2.44it/s][A
 51%|█████     | 51/100 [00:23<00:21,  2.28it/s][A
 52%|█████▏    | 52/100 [00:23<00:23,  2.05it/s][A
 53%|█████▎    | 53/100 [00:24<00:23,  1.99it/s][A
 54%|█████▍    | 54/100 [00:24<00:20,  2.22it/s][A
 55%|█████▌    | 55/100 [00:25<00:18,  2.47it/s][A
 56%|█████▌    | 56/100 [00:25<00:17,  2.54it/s][A
 57%|█████▋    | 57/100 [00:25<00:18,  2.34it/s][A
 58%|█████▊    | 58/100 [00:26<00:17,  2.36it/s][A
 59%|█████▉    | 59/100 [00:26<00:18,  2.23it/s][A
 60%|██████    | 60/100 [00:27<00:19,  2.02it/s][A
 61%|██████    | 61/100 [00:27<00:17,  2.17it/s][A
 62%|██████▏   | 62/100 [00:28<00:16,  2.33it/s][A
 63%|██████▎   | 63/100 [00:28<00:15,  2.44it/s][A
 64%|██████▍   | 64/100 [00:28<00:13,  2.58it/s][A
 65%|██████▌   | 65/100 [00:29<00:12,  2.71it/s][A
 66%|██████▌   | 66/100 [00:29<00:12,  2.74it/s][A
 67%|██████▋   | 67/100 [00:29<00:11,  2.87it/s][A
 68%|██████▊   | 68/100 [00:30<00:10,  2.96it/s][A
 69%|██████▉   | 69/100 [00:30<00:10,  2.92it/s][A
 70%|███████   | 70/100 [00:31<00:11,  2.69it/s][A
 71%|███████   | 71/100 [00:31<00:10,  2.82it/s][A
 72%|███████▏  | 72/100 [00:31<00:11,  2.44it/s][A
 73%|███████▎  | 73/100 [00:32<00:12,  2.11it/s][A
 74%|███████▍  | 74/100 [00:32<00:11,  2.21it/s][A
 75%|███████▌  | 75/100 [00:33<00:10,  2.45it/s][A
 76%|███████▌  | 76/100 [00:33<00:08,  2.69it/s][A
 77%|███████▋  | 77/100 [00:33<00:08,  2.75it/s][A
 78%|███████▊  | 78/100 [00:34<00:07,  2.90it/s][A
 79%|███████▉  | 79/100 [00:34<00:07,  2.66it/s][A
 80%|████████  | 80/100 [00:34<00:07,  2.69it/s][A
 81%|████████  | 81/100 [00:35<00:06,  2.78it/s][A
 82%|████████▏ | 82/100 [00:35<00:06,  2.61it/s][A
 83%|████████▎ | 83/100 [00:36<00:06,  2.67it/s][A
 84%|████████▍ | 84/100 [00:36<00:06,  2.48it/s][A
 85%|████████▌ | 85/100 [00:36<00:05,  2.59it/s][A
 86%|████████▌ | 86/100 [00:37<00:06,  2.31it/s][A
 87%|████████▋ | 87/100 [00:38<00:06,  2.11it/s][A
 88%|████████▊ | 88/100 [00:38<00:06,  1.95it/s][A
 89%|████████▉ | 89/100 [00:39<00:05,  1.84it/s][A
 90%|█████████ | 90/100 [00:39<00:05,  2.00it/s][A
 91%|█████████ | 91/100 [00:40<00:04,  1.99it/s][A
 92%|█████████▏| 92/100 [00:40<00:03,  2.23it/s][A
 93%|█████████▎| 93/100 [00:40<00:03,  2.12it/s][A
 94%|█████████▍| 94/100 [00:41<00:02,  2.10it/s][A
 95%|█████████▌| 95/100 [00:42<00:02,  2.03it/s][A
 96%|█████████▌| 96/100 [00:42<00:02,  1.93it/s][A
 97%|█████████▋| 97/100 [00:43<00:01,  1.83it/s][A
 98%|█████████▊| 98/100 [00:43<00:01,  1.97it/s][A
 99%|█████████▉| 99/100 [00:43<00:00,  2.20it/s][A
100%|██████████| 100/100 [00:44<00:00,  2.40it/s][A                                              
                                                 [A{'eval_loss': 2.1895503997802734, 'eval_runtime': 44.6993, 'eval_samples_per_second': 4.474, 'eval_steps_per_second': 2.237, 'epoch': 0.8}
 21%|██        | 5/24 [02:39<07:18, 23.07s/it]
100%|██████████| 100/100 [00:44<00:00,  2.40it/s][A
                                                 [A 25%|██▌       | 6/24 [03:02<11:26, 38.16s/it]/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 29%|██▉       | 7/24 [03:26<09:27, 33.38s/it] 33%|███▎      | 8/24 [03:46<07:48, 29.30s/it] 38%|███▊      | 9/24 [04:07<06:40, 26.69s/it] 42%|████▏     | 10/24 [04:30<05:58, 25.59s/it]
  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:28,  3.48it/s][A
  3%|▎         | 3/100 [00:00<00:32,  2.99it/s][A
  4%|▍         | 4/100 [00:01<00:37,  2.54it/s][A
  5%|▌         | 5/100 [00:01<00:38,  2.50it/s][A
  6%|▌         | 6/100 [00:02<00:40,  2.34it/s][A
  7%|▋         | 7/100 [00:02<00:43,  2.15it/s][A
  8%|▊         | 8/100 [00:03<00:44,  2.09it/s][A
  9%|▉         | 9/100 [00:03<00:43,  2.11it/s][A
 10%|█         | 10/100 [00:04<00:45,  1.98it/s][A
 11%|█         | 11/100 [00:05<00:47,  1.86it/s][A
 12%|█▏        | 12/100 [00:05<00:43,  2.01it/s][A
 13%|█▎        | 13/100 [00:05<00:39,  2.21it/s][A
 14%|█▍        | 14/100 [00:06<00:35,  2.44it/s][A
 15%|█▌        | 15/100 [00:06<00:31,  2.71it/s][A
 16%|█▌        | 16/100 [00:06<00:31,  2.64it/s][A
 17%|█▋        | 17/100 [00:07<00:33,  2.51it/s][A
 18%|█▊        | 18/100 [00:07<00:33,  2.43it/s][A
 19%|█▉        | 19/100 [00:08<00:31,  2.56it/s][A
 20%|██        | 20/100 [00:08<00:32,  2.48it/s][A
 21%|██        | 21/100 [00:08<00:29,  2.68it/s][A
 22%|██▏       | 22/100 [00:09<00:29,  2.60it/s][A
 23%|██▎       | 23/100 [00:09<00:32,  2.39it/s][A
 24%|██▍       | 24/100 [00:10<00:35,  2.12it/s][A
 25%|██▌       | 25/100 [00:10<00:38,  1.94it/s][A
 26%|██▌       | 26/100 [00:11<00:38,  1.92it/s][A
 27%|██▋       | 27/100 [00:11<00:35,  2.06it/s][A
 28%|██▊       | 28/100 [00:12<00:30,  2.35it/s][A
 29%|██▉       | 29/100 [00:12<00:31,  2.27it/s][A
 30%|███       | 30/100 [00:12<00:29,  2.35it/s][A
 31%|███       | 31/100 [00:13<00:30,  2.24it/s][A
 32%|███▏      | 32/100 [00:14<00:33,  2.03it/s][A
 33%|███▎      | 33/100 [00:14<00:31,  2.15it/s][A
 34%|███▍      | 34/100 [00:15<00:32,  2.03it/s][A
 35%|███▌      | 35/100 [00:15<00:34,  1.88it/s][A
 36%|███▌      | 36/100 [00:16<00:35,  1.79it/s][A
 37%|███▋      | 37/100 [00:16<00:36,  1.73it/s][A
 38%|███▊      | 38/100 [00:17<00:36,  1.71it/s][A
 39%|███▉      | 39/100 [00:18<00:36,  1.68it/s][A
 40%|████      | 40/100 [00:18<00:33,  1.77it/s][A
 41%|████      | 41/100 [00:18<00:29,  1.97it/s][A
 42%|████▏     | 42/100 [00:19<00:26,  2.16it/s][A
 43%|████▎     | 43/100 [00:19<00:23,  2.44it/s][A
 44%|████▍     | 44/100 [00:20<00:25,  2.24it/s][A
 45%|████▌     | 45/100 [00:20<00:24,  2.26it/s][A
 46%|████▌     | 46/100 [00:21<00:24,  2.23it/s][A
 47%|████▋     | 47/100 [00:21<00:26,  2.04it/s][A
 48%|████▊     | 48/100 [00:22<00:26,  1.98it/s][A
 49%|████▉     | 49/100 [00:22<00:22,  2.22it/s][A
 50%|█████     | 50/100 [00:22<00:20,  2.44it/s][A
 51%|█████     | 51/100 [00:23<00:21,  2.28it/s][A
 52%|█████▏    | 52/100 [00:23<00:23,  2.05it/s][A
 53%|█████▎    | 53/100 [00:24<00:23,  1.99it/s][A
 54%|█████▍    | 54/100 [00:24<00:20,  2.22it/s][A
 55%|█████▌    | 55/100 [00:25<00:18,  2.47it/s][A
 56%|█████▌    | 56/100 [00:25<00:17,  2.54it/s][A
 57%|█████▋    | 57/100 [00:25<00:18,  2.34it/s][A
 58%|█████▊    | 58/100 [00:26<00:17,  2.36it/s][A
 59%|█████▉    | 59/100 [00:26<00:18,  2.23it/s][A
 60%|██████    | 60/100 [00:27<00:19,  2.02it/s][A
 61%|██████    | 61/100 [00:27<00:18,  2.17it/s][A
 62%|██████▏   | 62/100 [00:28<00:16,  2.32it/s][A
 63%|██████▎   | 63/100 [00:28<00:15,  2.44it/s][A
 64%|██████▍   | 64/100 [00:28<00:13,  2.58it/s][A
 65%|██████▌   | 65/100 [00:29<00:12,  2.71it/s][A
 66%|██████▌   | 66/100 [00:29<00:12,  2.74it/s][A
 67%|██████▋   | 67/100 [00:29<00:11,  2.86it/s][A
 68%|██████▊   | 68/100 [00:30<00:10,  2.96it/s][A
 69%|██████▉   | 69/100 [00:30<00:10,  2.92it/s][A
 70%|███████   | 70/100 [00:31<00:11,  2.69it/s][A
 71%|███████   | 71/100 [00:31<00:10,  2.81it/s][A
 72%|███████▏  | 72/100 [00:31<00:11,  2.44it/s][A
 73%|███████▎  | 73/100 [00:32<00:12,  2.11it/s][A
 74%|███████▍  | 74/100 [00:32<00:11,  2.21it/s][A
 75%|███████▌  | 75/100 [00:33<00:10,  2.45it/s][A
 76%|███████▌  | 76/100 [00:33<00:08,  2.69it/s][A
 77%|███████▋  | 77/100 [00:33<00:08,  2.75it/s][A
 78%|███████▊  | 78/100 [00:34<00:07,  2.90it/s][A
 79%|███████▉  | 79/100 [00:34<00:07,  2.66it/s][A
 80%|████████  | 80/100 [00:34<00:07,  2.69it/s][A
 81%|████████  | 81/100 [00:35<00:06,  2.78it/s][A
 82%|████████▏ | 82/100 [00:35<00:06,  2.61it/s][A
 83%|████████▎ | 83/100 [00:36<00:06,  2.67it/s][A
 84%|████████▍ | 84/100 [00:36<00:06,  2.48it/s][A
 85%|████████▌ | 85/100 [00:36<00:05,  2.59it/s][A
 86%|████████▌ | 86/100 [00:37<00:06,  2.31it/s][A
 87%|████████▋ | 87/100 [00:38<00:06,  2.11it/s][A
 88%|████████▊ | 88/100 [00:38<00:06,  1.95it/s][A
 89%|████████▉ | 89/100 [00:39<00:05,  1.84it/s][A
 90%|█████████ | 90/100 [00:39<00:05,  2.00it/s][A
 91%|█████████ | 91/100 [00:40<00:04,  1.98it/s][A
 92%|█████████▏| 92/100 [00:40<00:03,  2.23it/s][A
 93%|█████████▎| 93/100 [00:40<00:03,  2.11it/s][A
 94%|█████████▍| 94/100 [00:41<00:02,  2.10it/s][A
 95%|█████████▌| 95/100 [00:42<00:02,  2.02it/s][A
 96%|█████████▌| 96/100 [00:42<00:02,  1.93it/s][A
 97%|█████████▋| 97/100 [00:43<00:01,  1.83it/s][A
 98%|█████████▊| 98/100 [00:43<00:01,  1.97it/s][A
 99%|█████████▉| 99/100 [00:43<00:00,  2.20it/s][A
100%|██████████| 100/100 [00:44<00:00,  2.40it/s][A                                               
                                                 [A{'eval_loss': 1.4605381488800049, 'eval_runtime': 44.7032, 'eval_samples_per_second': 4.474, 'eval_steps_per_second': 2.237, 'epoch': 1.6}
 42%|████▏     | 10/24 [05:15<05:58, 25.59s/it]
100%|██████████| 100/100 [00:44<00:00,  2.40it/s][A
                                                 [A 46%|████▌     | 11/24 [05:39<08:25, 38.92s/it] 50%|█████     | 12/24 [06:04<06:55, 34.65s/it]/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 54%|█████▍    | 13/24 [06:27<05:41, 31.06s/it] 58%|█████▊    | 14/24 [06:49<04:43, 28.33s/it] 62%|██████▎   | 15/24 [07:12<04:01, 26.83s/it]
  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:28,  3.47it/s][A
  3%|▎         | 3/100 [00:00<00:32,  2.98it/s][A
  4%|▍         | 4/100 [00:01<00:37,  2.54it/s][A
  5%|▌         | 5/100 [00:01<00:38,  2.50it/s][A
  6%|▌         | 6/100 [00:02<00:40,  2.34it/s][A
  7%|▋         | 7/100 [00:02<00:43,  2.15it/s][A
  8%|▊         | 8/100 [00:03<00:44,  2.09it/s][A
  9%|▉         | 9/100 [00:03<00:43,  2.11it/s][A
 10%|█         | 10/100 [00:04<00:45,  1.98it/s][A
 11%|█         | 11/100 [00:05<00:47,  1.86it/s][A
 12%|█▏        | 12/100 [00:05<00:43,  2.01it/s][A
 13%|█▎        | 13/100 [00:05<00:39,  2.21it/s][A
 14%|█▍        | 14/100 [00:06<00:35,  2.44it/s][A
 15%|█▌        | 15/100 [00:06<00:31,  2.71it/s][A
 16%|█▌        | 16/100 [00:06<00:31,  2.64it/s][A
 17%|█▋        | 17/100 [00:07<00:33,  2.51it/s][A
 18%|█▊        | 18/100 [00:07<00:33,  2.43it/s][A
 19%|█▉        | 19/100 [00:08<00:31,  2.55it/s][A
 20%|██        | 20/100 [00:08<00:32,  2.48it/s][A
 21%|██        | 21/100 [00:08<00:29,  2.68it/s][A
 22%|██▏       | 22/100 [00:09<00:30,  2.60it/s][A
 23%|██▎       | 23/100 [00:09<00:32,  2.39it/s][A
 24%|██▍       | 24/100 [00:10<00:35,  2.12it/s][A
 25%|██▌       | 25/100 [00:10<00:38,  1.94it/s][A
 26%|██▌       | 26/100 [00:11<00:38,  1.92it/s][A
 27%|██▋       | 27/100 [00:11<00:35,  2.06it/s][A
 28%|██▊       | 28/100 [00:12<00:30,  2.35it/s][A
 29%|██▉       | 29/100 [00:12<00:31,  2.26it/s][A
 30%|███       | 30/100 [00:12<00:29,  2.35it/s][A
 31%|███       | 31/100 [00:13<00:30,  2.24it/s][A
 32%|███▏      | 32/100 [00:14<00:33,  2.03it/s][A
 33%|███▎      | 33/100 [00:14<00:31,  2.15it/s][A
 34%|███▍      | 34/100 [00:15<00:32,  2.03it/s][A
 35%|███▌      | 35/100 [00:15<00:34,  1.88it/s][A
 36%|███▌      | 36/100 [00:16<00:35,  1.79it/s][A
 37%|███▋      | 37/100 [00:16<00:36,  1.73it/s][A
 38%|███▊      | 38/100 [00:17<00:36,  1.71it/s][A
 39%|███▉      | 39/100 [00:18<00:36,  1.68it/s][A
 40%|████      | 40/100 [00:18<00:33,  1.77it/s][A
 41%|████      | 41/100 [00:18<00:29,  1.97it/s][A
 42%|████▏     | 42/100 [00:19<00:26,  2.16it/s][A
 43%|████▎     | 43/100 [00:19<00:23,  2.44it/s][A
 44%|████▍     | 44/100 [00:20<00:25,  2.24it/s][A
 45%|████▌     | 45/100 [00:20<00:24,  2.26it/s][A
 46%|████▌     | 46/100 [00:21<00:24,  2.23it/s][A
 47%|████▋     | 47/100 [00:21<00:26,  2.03it/s][A
 48%|████▊     | 48/100 [00:22<00:26,  1.98it/s][A
 49%|████▉     | 49/100 [00:22<00:22,  2.22it/s][A
 50%|█████     | 50/100 [00:22<00:20,  2.43it/s][A
 51%|█████     | 51/100 [00:23<00:21,  2.28it/s][A
 52%|█████▏    | 52/100 [00:23<00:23,  2.05it/s][A
 53%|█████▎    | 53/100 [00:24<00:23,  1.99it/s][A
 54%|█████▍    | 54/100 [00:24<00:20,  2.22it/s][A
 55%|█████▌    | 55/100 [00:25<00:18,  2.47it/s][A
 56%|█████▌    | 56/100 [00:25<00:17,  2.54it/s][A
 57%|█████▋    | 57/100 [00:25<00:18,  2.34it/s][A
 58%|█████▊    | 58/100 [00:26<00:17,  2.36it/s][A
 59%|█████▉    | 59/100 [00:26<00:18,  2.23it/s][A
 60%|██████    | 60/100 [00:27<00:19,  2.02it/s][A
 61%|██████    | 61/100 [00:27<00:17,  2.17it/s][A
 62%|██████▏   | 62/100 [00:28<00:16,  2.32it/s][A
 63%|██████▎   | 63/100 [00:28<00:15,  2.44it/s][A
 64%|██████▍   | 64/100 [00:28<00:13,  2.58it/s][A
 65%|██████▌   | 65/100 [00:29<00:12,  2.71it/s][A
 66%|██████▌   | 66/100 [00:29<00:12,  2.74it/s][A
 67%|██████▋   | 67/100 [00:29<00:11,  2.87it/s][A
 68%|██████▊   | 68/100 [00:30<00:10,  2.96it/s][A
 69%|██████▉   | 69/100 [00:30<00:10,  2.92it/s][A
 70%|███████   | 70/100 [00:31<00:11,  2.69it/s][A
 71%|███████   | 71/100 [00:31<00:10,  2.82it/s][A
 72%|███████▏  | 72/100 [00:31<00:11,  2.44it/s][A
 73%|███████▎  | 73/100 [00:32<00:12,  2.11it/s][A
 74%|███████▍  | 74/100 [00:32<00:11,  2.21it/s][A
 75%|███████▌  | 75/100 [00:33<00:10,  2.45it/s][A
 76%|███████▌  | 76/100 [00:33<00:08,  2.69it/s][A
 77%|███████▋  | 77/100 [00:33<00:08,  2.75it/s][A
 78%|███████▊  | 78/100 [00:34<00:07,  2.90it/s][A
 79%|███████▉  | 79/100 [00:34<00:07,  2.66it/s][A
 80%|████████  | 80/100 [00:34<00:07,  2.69it/s][A
 81%|████████  | 81/100 [00:35<00:06,  2.78it/s][A
 82%|████████▏ | 82/100 [00:35<00:06,  2.61it/s][A
 83%|████████▎ | 83/100 [00:36<00:06,  2.67it/s][A
 84%|████████▍ | 84/100 [00:36<00:06,  2.48it/s][A
 85%|████████▌ | 85/100 [00:36<00:05,  2.59it/s][A
 86%|████████▌ | 86/100 [00:37<00:06,  2.31it/s][A
 87%|████████▋ | 87/100 [00:38<00:06,  2.11it/s][A
 88%|████████▊ | 88/100 [00:38<00:06,  1.95it/s][A
 89%|████████▉ | 89/100 [00:39<00:05,  1.84it/s][A
 90%|█████████ | 90/100 [00:39<00:05,  2.00it/s][A
 91%|█████████ | 91/100 [00:40<00:04,  1.98it/s][A
 92%|█████████▏| 92/100 [00:40<00:03,  2.23it/s][A
 93%|█████████▎| 93/100 [00:41<00:03,  2.12it/s][A
 94%|█████████▍| 94/100 [00:41<00:02,  2.10it/s][A
 95%|█████████▌| 95/100 [00:42<00:02,  2.02it/s][A
 96%|█████████▌| 96/100 [00:42<00:02,  1.93it/s][A
 97%|█████████▋| 97/100 [00:43<00:01,  1.83it/s][A
 98%|█████████▊| 98/100 [00:43<00:01,  1.97it/s][A
 99%|█████████▉| 99/100 [00:43<00:00,  2.20it/s][A
100%|██████████| 100/100 [00:44<00:00,  2.40it/s][A                                               
                                                 [A{'eval_loss': 1.2937453985214233, 'eval_runtime': 44.7136, 'eval_samples_per_second': 4.473, 'eval_steps_per_second': 2.236, 'epoch': 2.4}
 62%|██████▎   | 15/24 [07:57<04:01, 26.83s/it]
100%|██████████| 100/100 [00:44<00:00,  2.40it/s][A
                                                 [A 67%|██████▋   | 16/24 [08:21<05:15, 39.47s/it] 71%|███████   | 17/24 [08:43<03:59, 34.24s/it] 75%|███████▌  | 18/24 [09:04<03:01, 30.24s/it]/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 79%|███████▉  | 19/24 [09:26<02:18, 27.77s/it] 83%|████████▎ | 20/24 [09:48<01:43, 25.82s/it]
  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:28,  3.48it/s][A
  3%|▎         | 3/100 [00:00<00:32,  2.98it/s][A
  4%|▍         | 4/100 [00:01<00:37,  2.54it/s][A
  5%|▌         | 5/100 [00:01<00:38,  2.49it/s][A
  6%|▌         | 6/100 [00:02<00:40,  2.34it/s][A
  7%|▋         | 7/100 [00:02<00:43,  2.15it/s][A
  8%|▊         | 8/100 [00:03<00:44,  2.09it/s][A
  9%|▉         | 9/100 [00:03<00:43,  2.11it/s][A
 10%|█         | 10/100 [00:04<00:45,  1.98it/s][A
 11%|█         | 11/100 [00:05<00:47,  1.86it/s][A
 12%|█▏        | 12/100 [00:05<00:43,  2.01it/s][A
 13%|█▎        | 13/100 [00:05<00:39,  2.21it/s][A
 14%|█▍        | 14/100 [00:06<00:35,  2.44it/s][A
 15%|█▌        | 15/100 [00:06<00:31,  2.71it/s][A
 16%|█▌        | 16/100 [00:06<00:31,  2.65it/s][A
 17%|█▋        | 17/100 [00:07<00:33,  2.51it/s][A
 18%|█▊        | 18/100 [00:07<00:33,  2.43it/s][A
 19%|█▉        | 19/100 [00:08<00:31,  2.55it/s][A
 20%|██        | 20/100 [00:08<00:32,  2.48it/s][A
 21%|██        | 21/100 [00:08<00:29,  2.68it/s][A
 22%|██▏       | 22/100 [00:09<00:30,  2.60it/s][A
 23%|██▎       | 23/100 [00:09<00:32,  2.39it/s][A
 24%|██▍       | 24/100 [00:10<00:35,  2.12it/s][A
 25%|██▌       | 25/100 [00:10<00:38,  1.94it/s][A
 26%|██▌       | 26/100 [00:11<00:38,  1.92it/s][A
 27%|██▋       | 27/100 [00:11<00:35,  2.06it/s][A
 28%|██▊       | 28/100 [00:12<00:30,  2.36it/s][A
 29%|██▉       | 29/100 [00:12<00:31,  2.27it/s][A
 30%|███       | 30/100 [00:12<00:29,  2.35it/s][A
 31%|███       | 31/100 [00:13<00:30,  2.24it/s][A
 32%|███▏      | 32/100 [00:14<00:33,  2.03it/s][A
 33%|███▎      | 33/100 [00:14<00:31,  2.15it/s][A
 34%|███▍      | 34/100 [00:15<00:32,  2.03it/s][A
 35%|███▌      | 35/100 [00:15<00:34,  1.88it/s][A
 36%|███▌      | 36/100 [00:16<00:35,  1.79it/s][A
 37%|███▋      | 37/100 [00:16<00:36,  1.73it/s][A
 38%|███▊      | 38/100 [00:17<00:36,  1.71it/s][A
 39%|███▉      | 39/100 [00:18<00:36,  1.68it/s][A
 40%|████      | 40/100 [00:18<00:33,  1.77it/s][A
 41%|████      | 41/100 [00:18<00:29,  1.97it/s][A
 42%|████▏     | 42/100 [00:19<00:26,  2.16it/s][A
 43%|████▎     | 43/100 [00:19<00:23,  2.44it/s][A
 44%|████▍     | 44/100 [00:20<00:25,  2.24it/s][A
 45%|████▌     | 45/100 [00:20<00:24,  2.26it/s][A
 46%|████▌     | 46/100 [00:21<00:24,  2.23it/s][A
 47%|████▋     | 47/100 [00:21<00:26,  2.04it/s][A
 48%|████▊     | 48/100 [00:22<00:26,  1.98it/s][A
 49%|████▉     | 49/100 [00:22<00:22,  2.22it/s][A
 50%|█████     | 50/100 [00:22<00:20,  2.43it/s][A
 51%|█████     | 51/100 [00:23<00:21,  2.28it/s][A
 52%|█████▏    | 52/100 [00:23<00:23,  2.05it/s][A
 53%|█████▎    | 53/100 [00:24<00:23,  1.99it/s][A
 54%|█████▍    | 54/100 [00:24<00:20,  2.22it/s][A
 55%|█████▌    | 55/100 [00:25<00:18,  2.47it/s][A
 56%|█████▌    | 56/100 [00:25<00:17,  2.54it/s][A
 57%|█████▋    | 57/100 [00:25<00:18,  2.34it/s][A
 58%|█████▊    | 58/100 [00:26<00:17,  2.36it/s][A
 59%|█████▉    | 59/100 [00:26<00:18,  2.23it/s][A
 60%|██████    | 60/100 [00:27<00:19,  2.02it/s][A
 61%|██████    | 61/100 [00:27<00:18,  2.17it/s][A
 62%|██████▏   | 62/100 [00:28<00:16,  2.32it/s][A
 63%|██████▎   | 63/100 [00:28<00:15,  2.44it/s][A
 64%|██████▍   | 64/100 [00:28<00:13,  2.58it/s][A
 65%|██████▌   | 65/100 [00:29<00:12,  2.71it/s][A
 66%|██████▌   | 66/100 [00:29<00:12,  2.74it/s][A
 67%|██████▋   | 67/100 [00:29<00:11,  2.86it/s][A
 68%|██████▊   | 68/100 [00:30<00:10,  2.96it/s][A
 69%|██████▉   | 69/100 [00:30<00:10,  2.92it/s][A
 70%|███████   | 70/100 [00:31<00:11,  2.70it/s][A
 71%|███████   | 71/100 [00:31<00:10,  2.82it/s][A
 72%|███████▏  | 72/100 [00:31<00:11,  2.44it/s][A
 73%|███████▎  | 73/100 [00:32<00:12,  2.11it/s][A
 74%|███████▍  | 74/100 [00:32<00:11,  2.21it/s][A
 75%|███████▌  | 75/100 [00:33<00:10,  2.45it/s][A
 76%|███████▌  | 76/100 [00:33<00:08,  2.69it/s][A
 77%|███████▋  | 77/100 [00:33<00:08,  2.75it/s][A
 78%|███████▊  | 78/100 [00:34<00:07,  2.90it/s][A
 79%|███████▉  | 79/100 [00:34<00:07,  2.66it/s][A
 80%|████████  | 80/100 [00:34<00:07,  2.69it/s][A
 81%|████████  | 81/100 [00:35<00:06,  2.78it/s][A
 82%|████████▏ | 82/100 [00:35<00:06,  2.61it/s][A
 83%|████████▎ | 83/100 [00:36<00:06,  2.67it/s][A
 84%|████████▍ | 84/100 [00:36<00:06,  2.48it/s][A
 85%|████████▌ | 85/100 [00:36<00:05,  2.60it/s][A
 86%|████████▌ | 86/100 [00:37<00:06,  2.31it/s][A
 87%|████████▋ | 87/100 [00:38<00:06,  2.12it/s][A
 88%|████████▊ | 88/100 [00:38<00:06,  1.95it/s][A
 89%|████████▉ | 89/100 [00:39<00:05,  1.84it/s][A
 90%|█████████ | 90/100 [00:39<00:05,  2.00it/s][A
 91%|█████████ | 91/100 [00:40<00:04,  1.99it/s][A
 92%|█████████▏| 92/100 [00:40<00:03,  2.23it/s][A
 93%|█████████▎| 93/100 [00:40<00:03,  2.12it/s][A
 94%|█████████▍| 94/100 [00:41<00:02,  2.10it/s][A
 95%|█████████▌| 95/100 [00:42<00:02,  2.03it/s][A
 96%|█████████▌| 96/100 [00:42<00:02,  1.93it/s][A
 97%|█████████▋| 97/100 [00:43<00:01,  1.83it/s][A
 98%|█████████▊| 98/100 [00:43<00:01,  1.97it/s][A
 99%|█████████▉| 99/100 [00:43<00:00,  2.20it/s][A
100%|██████████| 100/100 [00:44<00:00,  2.40it/s][A                                               
                                                 [A{'eval_loss': 1.199320912361145, 'eval_runtime': 44.696, 'eval_samples_per_second': 4.475, 'eval_steps_per_second': 2.237, 'epoch': 3.2}
 83%|████████▎ | 20/24 [10:32<01:43, 25.82s/it]
100%|██████████| 100/100 [00:44<00:00,  2.40it/s][A
                                                 [A 88%|████████▊ | 21/24 [10:55<01:55, 38.47s/it] 92%|█████████▏| 22/24 [11:21<01:09, 34.56s/it] 96%|█████████▌| 23/24 [11:44<00:31, 31.06s/it]100%|██████████| 24/24 [12:06<00:00, 28.47s/it]                                               {'train_runtime': 727.0136, 'train_samples_per_second': 1.1, 'train_steps_per_second': 0.033, 'train_loss': 1.5802545547485352, 'epoch': 3.84}
100%|██████████| 24/24 [12:07<00:00, 28.47s/it]100%|██████████| 24/24 [12:07<00:00, 30.29s/it]
trainer.state.log_history:  [{'eval_loss': 2.1895503997802734, 'eval_runtime': 44.6993, 'eval_samples_per_second': 4.474, 'eval_steps_per_second': 2.237, 'epoch': 0.8, 'step': 5}, {'eval_loss': 1.4605381488800049, 'eval_runtime': 44.7032, 'eval_samples_per_second': 4.474, 'eval_steps_per_second': 2.237, 'epoch': 1.6, 'step': 10}, {'eval_loss': 1.2937453985214233, 'eval_runtime': 44.7136, 'eval_samples_per_second': 4.473, 'eval_steps_per_second': 2.236, 'epoch': 2.4, 'step': 15}, {'eval_loss': 1.199320912361145, 'eval_runtime': 44.696, 'eval_samples_per_second': 4.475, 'eval_steps_per_second': 2.237, 'epoch': 3.2, 'step': 20}, {'train_runtime': 727.0136, 'train_samples_per_second': 1.1, 'train_steps_per_second': 0.033, 'total_flos': 8981658262241280.0, 'train_loss': 1.5802545547485352, 'epoch': 3.84, 'step': 24}]
train_results:  TrainOutput(global_step=24, training_loss=1.5802545547485352, metrics={'train_runtime': 727.0136, 'train_samples_per_second': 1.1, 'train_steps_per_second': 0.033, 'train_loss': 1.5802545547485352, 'epoch': 3.84})
train loss: 1.5802545547485352
Traceback (most recent call last):
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 194, in <module>
    plot_loss(trainer.state.log_history, f'Output_files/loss_plot_lr_{lr_scientific}_ep_{training_arguments.num_train_epochs}_ba_{training_arguments.per_device_train_batch_size}.png')
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 111, in plot_loss
    plt.plot(steps, eval_loss, label='Evaluation Loss', marker='o', color=colors[1])
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/pyplot.py", line 3590, in plot
    return gca().plot(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (0,) and (4,)
batch: 4
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  2.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.09s/it]
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2364.79 examples/s]
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2218.76 examples/s]
  0%|          | 0/12 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  8%|▊         | 1/12 [00:42<07:43, 42.17s/it] 17%|█▋        | 2/12 [01:23<06:58, 41.80s/it] 25%|██▌       | 3/12 [02:08<06:28, 43.14s/it]
  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:22,  2.14it/s][A
  6%|▌         | 3/50 [00:01<00:29,  1.62it/s][A
  8%|▊         | 4/50 [00:02<00:33,  1.37it/s][A
 10%|█         | 5/50 [00:03<00:37,  1.20it/s][A
 12%|█▏        | 6/50 [00:04<00:39,  1.11it/s][A
 14%|█▍        | 7/50 [00:05<00:35,  1.22it/s][A
 16%|█▌        | 8/50 [00:06<00:32,  1.31it/s][A
 18%|█▊        | 9/50 [00:06<00:30,  1.36it/s][A
 20%|██        | 10/50 [00:07<00:29,  1.38it/s][A
 22%|██▏       | 11/50 [00:08<00:28,  1.39it/s][A
 24%|██▍       | 12/50 [00:09<00:30,  1.25it/s][A
 26%|██▌       | 13/50 [00:10<00:32,  1.14it/s][A
 28%|██▊       | 14/50 [00:10<00:29,  1.22it/s][A
 30%|███       | 15/50 [00:11<00:28,  1.22it/s][A
 32%|███▏      | 16/50 [00:12<00:29,  1.13it/s][A
 34%|███▍      | 17/50 [00:13<00:30,  1.07it/s][A
 36%|███▌      | 18/50 [00:14<00:31,  1.03it/s][A
 38%|███▊      | 19/50 [00:15<00:31,  1.00s/it][A
 40%|████      | 20/50 [00:16<00:30,  1.02s/it][A
 42%|████▏     | 21/50 [00:17<00:26,  1.10it/s][A
 44%|████▍     | 22/50 [00:18<00:25,  1.09it/s][A
 46%|████▌     | 23/50 [00:19<00:24,  1.12it/s][A
 48%|████▊     | 24/50 [00:20<00:24,  1.08it/s][A
 50%|█████     | 25/50 [00:21<00:20,  1.19it/s][A
 52%|█████▏    | 26/50 [00:21<00:20,  1.16it/s][A
 54%|█████▍    | 27/50 [00:22<00:19,  1.16it/s][A
 56%|█████▌    | 28/50 [00:23<00:17,  1.25it/s][A
 58%|█████▊    | 29/50 [00:24<00:17,  1.23it/s][A
 60%|██████    | 30/50 [00:25<00:17,  1.14it/s][A
 62%|██████▏   | 31/50 [00:26<00:15,  1.22it/s][A
 64%|██████▍   | 32/50 [00:26<00:13,  1.36it/s][A
 66%|██████▌   | 33/50 [00:27<00:11,  1.48it/s][A
 68%|██████▊   | 34/50 [00:27<00:09,  1.62it/s][A
 70%|███████   | 35/50 [00:28<00:09,  1.59it/s][A
 72%|███████▏  | 36/50 [00:29<00:10,  1.36it/s][A
 74%|███████▍  | 37/50 [00:30<00:10,  1.20it/s][A
 76%|███████▌  | 38/50 [00:30<00:08,  1.34it/s][A
 78%|███████▊  | 39/50 [00:31<00:07,  1.49it/s][A
 80%|████████  | 40/50 [00:32<00:06,  1.44it/s][A
 82%|████████▏ | 41/50 [00:32<00:06,  1.41it/s][A
 84%|████████▍ | 42/50 [00:33<00:05,  1.36it/s][A
 86%|████████▌ | 43/50 [00:34<00:05,  1.23it/s][A
 88%|████████▊ | 44/50 [00:35<00:05,  1.12it/s][A
 90%|█████████ | 45/50 [00:36<00:04,  1.07it/s][A
 92%|█████████▏| 46/50 [00:37<00:03,  1.06it/s][A
 94%|█████████▍| 47/50 [00:38<00:02,  1.03it/s][A
 96%|█████████▌| 48/50 [00:39<00:01,  1.03it/s][A
 98%|█████████▊| 49/50 [00:40<00:00,  1.01it/s][A
100%|██████████| 50/50 [00:41<00:00,  1.13it/s][A                                              
                                               [A{'eval_loss': 2.3892104625701904, 'eval_runtime': 42.2608, 'eval_samples_per_second': 4.733, 'eval_steps_per_second': 1.183, 'epoch': 0.96}
 25%|██▌       | 3/12 [02:50<06:28, 43.14s/it]
100%|██████████| 50/50 [00:41<00:00,  1.13it/s][A
                                               [A/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 33%|███▎      | 4/12 [03:33<07:57, 59.65s/it] 42%|████▏     | 5/12 [04:16<06:16, 53.81s/it] 50%|█████     | 6/12 [05:03<05:07, 51.31s/it]
  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:22,  2.14it/s][A
  6%|▌         | 3/50 [00:01<00:29,  1.62it/s][A
  8%|▊         | 4/50 [00:02<00:33,  1.37it/s][A
 10%|█         | 5/50 [00:03<00:37,  1.20it/s][A
 12%|█▏        | 6/50 [00:04<00:39,  1.11it/s][A
 14%|█▍        | 7/50 [00:05<00:35,  1.22it/s][A
 16%|█▌        | 8/50 [00:06<00:31,  1.31it/s][A
 18%|█▊        | 9/50 [00:06<00:30,  1.36it/s][A
 20%|██        | 10/50 [00:07<00:29,  1.38it/s][A
 22%|██▏       | 11/50 [00:08<00:28,  1.39it/s][A
 24%|██▍       | 12/50 [00:09<00:30,  1.25it/s][A
 26%|██▌       | 13/50 [00:10<00:32,  1.14it/s][A
 28%|██▊       | 14/50 [00:10<00:29,  1.22it/s][A
 30%|███       | 15/50 [00:11<00:28,  1.22it/s][A
 32%|███▏      | 16/50 [00:12<00:29,  1.14it/s][A
 34%|███▍      | 17/50 [00:13<00:30,  1.07it/s][A
 36%|███▌      | 18/50 [00:14<00:31,  1.03it/s][A
 38%|███▊      | 19/50 [00:15<00:31,  1.00s/it][A
 40%|████      | 20/50 [00:16<00:30,  1.02s/it][A
 42%|████▏     | 21/50 [00:17<00:26,  1.10it/s][A
 44%|████▍     | 22/50 [00:18<00:25,  1.09it/s][A
 46%|████▌     | 23/50 [00:19<00:24,  1.12it/s][A
 48%|████▊     | 24/50 [00:20<00:24,  1.08it/s][A
 50%|█████     | 25/50 [00:21<00:20,  1.19it/s][A
 52%|█████▏    | 26/50 [00:21<00:20,  1.16it/s][A
 54%|█████▍    | 27/50 [00:22<00:19,  1.15it/s][A
 56%|█████▌    | 28/50 [00:23<00:17,  1.25it/s][A
 58%|█████▊    | 29/50 [00:24<00:17,  1.23it/s][A
 60%|██████    | 30/50 [00:25<00:17,  1.14it/s][A
 62%|██████▏   | 31/50 [00:25<00:15,  1.22it/s][A
 64%|██████▍   | 32/50 [00:26<00:13,  1.36it/s][A
 66%|██████▌   | 33/50 [00:27<00:11,  1.48it/s][A
 68%|██████▊   | 34/50 [00:27<00:09,  1.62it/s][A
 70%|███████   | 35/50 [00:28<00:09,  1.59it/s][A
 72%|███████▏  | 36/50 [00:29<00:10,  1.37it/s][A
 74%|███████▍  | 37/50 [00:30<00:10,  1.20it/s][A
 76%|███████▌  | 38/50 [00:30<00:08,  1.34it/s][A
 78%|███████▊  | 39/50 [00:31<00:07,  1.49it/s][A
 80%|████████  | 40/50 [00:32<00:06,  1.44it/s][A
 82%|████████▏ | 41/50 [00:32<00:06,  1.41it/s][A
 84%|████████▍ | 42/50 [00:33<00:05,  1.36it/s][A
 86%|████████▌ | 43/50 [00:34<00:05,  1.23it/s][A
 88%|████████▊ | 44/50 [00:35<00:05,  1.12it/s][A
 90%|█████████ | 45/50 [00:36<00:04,  1.07it/s][A
 92%|█████████▏| 46/50 [00:37<00:03,  1.06it/s][A
 94%|█████████▍| 47/50 [00:38<00:02,  1.03it/s][A
 96%|█████████▌| 48/50 [00:39<00:01,  1.03it/s][A
 98%|█████████▊| 49/50 [00:40<00:00,  1.01it/s][A
100%|██████████| 50/50 [00:41<00:00,  1.13it/s][A                                              
                                               [A{'eval_loss': 1.9025468826293945, 'eval_runtime': 42.2462, 'eval_samples_per_second': 4.734, 'eval_steps_per_second': 1.184, 'epoch': 1.92}
 50%|█████     | 6/12 [05:45<05:07, 51.31s/it]
100%|██████████| 50/50 [00:41<00:00,  1.13it/s][A
                                               [A/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 58%|█████▊    | 7/12 [06:29<05:13, 62.63s/it] 67%|██████▋   | 8/12 [07:14<03:48, 57.21s/it] 75%|███████▌  | 9/12 [07:54<02:34, 51.66s/it]
  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:22,  2.14it/s][A
  6%|▌         | 3/50 [00:01<00:28,  1.62it/s][A
  8%|▊         | 4/50 [00:02<00:33,  1.38it/s][A
 10%|█         | 5/50 [00:03<00:37,  1.20it/s][A
 12%|█▏        | 6/50 [00:04<00:39,  1.11it/s][A
 14%|█▍        | 7/50 [00:05<00:35,  1.22it/s][A
 16%|█▌        | 8/50 [00:06<00:31,  1.31it/s][A
 18%|█▊        | 9/50 [00:06<00:30,  1.36it/s][A
 20%|██        | 10/50 [00:07<00:29,  1.38it/s][A
 22%|██▏       | 11/50 [00:08<00:28,  1.39it/s][A
 24%|██▍       | 12/50 [00:09<00:30,  1.25it/s][A
 26%|██▌       | 13/50 [00:10<00:32,  1.14it/s][A
 28%|██▊       | 14/50 [00:10<00:29,  1.23it/s][A
 30%|███       | 15/50 [00:11<00:28,  1.22it/s][A
 32%|███▏      | 16/50 [00:12<00:29,  1.14it/s][A
 34%|███▍      | 17/50 [00:13<00:30,  1.07it/s][A
 36%|███▌      | 18/50 [00:14<00:31,  1.03it/s][A
 38%|███▊      | 19/50 [00:15<00:30,  1.00it/s][A
 40%|████      | 20/50 [00:16<00:30,  1.02s/it][A
 42%|████▏     | 21/50 [00:17<00:26,  1.10it/s][A
 44%|████▍     | 22/50 [00:18<00:25,  1.09it/s][A
 46%|████▌     | 23/50 [00:19<00:24,  1.12it/s][A
 48%|████▊     | 24/50 [00:20<00:24,  1.08it/s][A
 50%|█████     | 25/50 [00:20<00:20,  1.20it/s][A
 52%|█████▏    | 26/50 [00:21<00:20,  1.16it/s][A
 54%|█████▍    | 27/50 [00:22<00:19,  1.16it/s][A
 56%|█████▌    | 28/50 [00:23<00:17,  1.25it/s][A
 58%|█████▊    | 29/50 [00:24<00:17,  1.23it/s][A
 60%|██████    | 30/50 [00:25<00:17,  1.15it/s][A
 62%|██████▏   | 31/50 [00:25<00:15,  1.22it/s][A
 64%|██████▍   | 32/50 [00:26<00:13,  1.36it/s][A
 66%|██████▌   | 33/50 [00:27<00:11,  1.48it/s][A
 68%|██████▊   | 34/50 [00:27<00:09,  1.62it/s][A
 70%|███████   | 35/50 [00:28<00:09,  1.59it/s][A
 72%|███████▏  | 36/50 [00:29<00:10,  1.37it/s][A
 74%|███████▍  | 37/50 [00:30<00:10,  1.20it/s][A
 76%|███████▌  | 38/50 [00:30<00:08,  1.35it/s][A
 78%|███████▊  | 39/50 [00:31<00:07,  1.49it/s][A
 80%|████████  | 40/50 [00:32<00:06,  1.44it/s][A
 82%|████████▏ | 41/50 [00:32<00:06,  1.41it/s][A
 84%|████████▍ | 42/50 [00:33<00:05,  1.36it/s][A
 86%|████████▌ | 43/50 [00:34<00:05,  1.23it/s][A
 88%|████████▊ | 44/50 [00:35<00:05,  1.13it/s][A
 90%|█████████ | 45/50 [00:36<00:04,  1.07it/s][A
 92%|█████████▏| 46/50 [00:37<00:03,  1.06it/s][A
 94%|█████████▍| 47/50 [00:38<00:02,  1.03it/s][A
 96%|█████████▌| 48/50 [00:39<00:01,  1.03it/s][A
 98%|█████████▊| 49/50 [00:40<00:00,  1.01it/s][A
100%|██████████| 50/50 [00:41<00:00,  1.14it/s][A                                              
                                               [A{'eval_loss': 1.5374412536621094, 'eval_runtime': 42.2014, 'eval_samples_per_second': 4.739, 'eval_steps_per_second': 1.185, 'epoch': 2.88}
 75%|███████▌  | 9/12 [08:36<02:34, 51.66s/it]
100%|██████████| 50/50 [00:41<00:00,  1.14it/s][A
                                               [A/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 83%|████████▎ | 10/12 [09:17<02:02, 61.48s/it] 92%|█████████▏| 11/12 [10:03<00:56, 56.55s/it]100%|██████████| 12/12 [10:46<00:00, 52.64s/it]
  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:22,  2.14it/s][A
  6%|▌         | 3/50 [00:01<00:29,  1.62it/s][A
  8%|▊         | 4/50 [00:02<00:33,  1.37it/s][A
 10%|█         | 5/50 [00:03<00:37,  1.20it/s][A
 12%|█▏        | 6/50 [00:04<00:39,  1.11it/s][A
 14%|█▍        | 7/50 [00:05<00:35,  1.22it/s][A
 16%|█▌        | 8/50 [00:06<00:31,  1.31it/s][A
 18%|█▊        | 9/50 [00:06<00:30,  1.36it/s][A
 20%|██        | 10/50 [00:07<00:29,  1.38it/s][A
 22%|██▏       | 11/50 [00:08<00:28,  1.39it/s][A
 24%|██▍       | 12/50 [00:09<00:30,  1.25it/s][A
 26%|██▌       | 13/50 [00:10<00:32,  1.14it/s][A
 28%|██▊       | 14/50 [00:10<00:29,  1.23it/s][A
 30%|███       | 15/50 [00:11<00:28,  1.22it/s][A
 32%|███▏      | 16/50 [00:12<00:29,  1.14it/s][A
 34%|███▍      | 17/50 [00:13<00:30,  1.07it/s][A
 36%|███▌      | 18/50 [00:14<00:31,  1.03it/s][A
 38%|███▊      | 19/50 [00:15<00:30,  1.00it/s][A
 40%|████      | 20/50 [00:16<00:30,  1.02s/it][A
 42%|████▏     | 21/50 [00:17<00:26,  1.10it/s][A
 44%|████▍     | 22/50 [00:18<00:25,  1.09it/s][A
 46%|████▌     | 23/50 [00:19<00:24,  1.12it/s][A
 48%|████▊     | 24/50 [00:20<00:24,  1.08it/s][A
 50%|█████     | 25/50 [00:20<00:20,  1.19it/s][A
 52%|█████▏    | 26/50 [00:21<00:20,  1.16it/s][A
 54%|█████▍    | 27/50 [00:22<00:19,  1.16it/s][A
 56%|█████▌    | 28/50 [00:23<00:17,  1.25it/s][A
 58%|█████▊    | 29/50 [00:24<00:17,  1.23it/s][A
 60%|██████    | 30/50 [00:25<00:17,  1.14it/s][A
 62%|██████▏   | 31/50 [00:25<00:15,  1.22it/s][A
 64%|██████▍   | 32/50 [00:26<00:13,  1.36it/s][A
 66%|██████▌   | 33/50 [00:27<00:11,  1.48it/s][A
 68%|██████▊   | 34/50 [00:27<00:09,  1.62it/s][A
 70%|███████   | 35/50 [00:28<00:09,  1.59it/s][A
 72%|███████▏  | 36/50 [00:29<00:10,  1.37it/s][A
 74%|███████▍  | 37/50 [00:30<00:10,  1.20it/s][A
 76%|███████▌  | 38/50 [00:30<00:08,  1.35it/s][A
 78%|███████▊  | 39/50 [00:31<00:07,  1.49it/s][A
 80%|████████  | 40/50 [00:32<00:06,  1.44it/s][A
 82%|████████▏ | 41/50 [00:32<00:06,  1.41it/s][A
 84%|████████▍ | 42/50 [00:33<00:05,  1.36it/s][A
 86%|████████▌ | 43/50 [00:34<00:05,  1.23it/s][A
 88%|████████▊ | 44/50 [00:35<00:05,  1.12it/s][A
 90%|█████████ | 45/50 [00:36<00:04,  1.07it/s][A
 92%|█████████▏| 46/50 [00:37<00:03,  1.06it/s][A
 94%|█████████▍| 47/50 [00:38<00:02,  1.03it/s][A
 96%|█████████▌| 48/50 [00:39<00:01,  1.03it/s][A
 98%|█████████▊| 49/50 [00:40<00:00,  1.01it/s][A
100%|██████████| 50/50 [00:41<00:00,  1.14it/s][A                                               
                                               [A{'eval_loss': 1.327337384223938, 'eval_runtime': 42.2234, 'eval_samples_per_second': 4.737, 'eval_steps_per_second': 1.184, 'epoch': 3.84}
100%|██████████| 12/12 [11:29<00:00, 52.64s/it]
100%|██████████| 50/50 [00:41<00:00,  1.14it/s][A
                                               [A                                               {'train_runtime': 689.3111, 'train_samples_per_second': 1.161, 'train_steps_per_second': 0.017, 'train_loss': 1.9381704330444336, 'epoch': 3.84}
100%|██████████| 12/12 [11:29<00:00, 52.64s/it]100%|██████████| 12/12 [11:29<00:00, 57.44s/it]
trainer.state.log_history:  [{'eval_loss': 2.3892104625701904, 'eval_runtime': 42.2608, 'eval_samples_per_second': 4.733, 'eval_steps_per_second': 1.183, 'epoch': 0.96, 'step': 3}, {'eval_loss': 1.9025468826293945, 'eval_runtime': 42.2462, 'eval_samples_per_second': 4.734, 'eval_steps_per_second': 1.184, 'epoch': 1.92, 'step': 6}, {'eval_loss': 1.5374412536621094, 'eval_runtime': 42.2014, 'eval_samples_per_second': 4.739, 'eval_steps_per_second': 1.185, 'epoch': 2.88, 'step': 9}, {'eval_loss': 1.327337384223938, 'eval_runtime': 42.2234, 'eval_samples_per_second': 4.737, 'eval_steps_per_second': 1.184, 'epoch': 3.84, 'step': 12}, {'train_runtime': 689.3111, 'train_samples_per_second': 1.161, 'train_steps_per_second': 0.017, 'total_flos': 1.125804622086144e+16, 'train_loss': 1.9381704330444336, 'epoch': 3.84, 'step': 12}]
train_results:  TrainOutput(global_step=12, training_loss=1.9381704330444336, metrics={'train_runtime': 689.3111, 'train_samples_per_second': 1.161, 'train_steps_per_second': 0.017, 'train_loss': 1.9381704330444336, 'epoch': 3.84})
train loss: 1.9381704330444336
Traceback (most recent call last):
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 194, in <module>
    plot_loss(trainer.state.log_history, f'Output_files/loss_plot_lr_{lr_scientific}_ep_{training_arguments.num_train_epochs}_ba_{training_arguments.per_device_train_batch_size}.png')
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 111, in plot_loss
    plt.plot(steps, eval_loss, label='Evaluation Loss', marker='o', color=colors[1])
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/pyplot.py", line 3590, in plot
    return gca().plot(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (0,) and (4,)
batch: 8
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.24s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.65s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  2.85s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.03s/it]
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2298.44 examples/s]
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2139.63 examples/s]
  0%|          | 0/4 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 25%|██▌       | 1/4 [01:26<04:20, 86.94s/it]
  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:01<00:19,  1.15it/s][A
 12%|█▏        | 3/25 [00:03<00:28,  1.29s/it][A
 16%|█▌        | 4/25 [00:04<00:27,  1.29s/it][A
 20%|██        | 5/25 [00:06<00:24,  1.25s/it][A
 24%|██▍       | 6/25 [00:07<00:26,  1.42s/it][A
 28%|██▊       | 7/25 [00:09<00:28,  1.59s/it][A
 32%|███▏      | 8/25 [00:11<00:28,  1.70s/it][A
 36%|███▌      | 9/25 [00:13<00:28,  1.77s/it][A
 40%|████      | 10/25 [00:15<00:27,  1.82s/it][A
 44%|████▍     | 11/25 [00:17<00:26,  1.86s/it][A
 48%|████▊     | 12/25 [00:19<00:24,  1.88s/it][A
 52%|█████▏    | 13/25 [00:21<00:22,  1.90s/it][A
 56%|█████▌    | 14/25 [00:22<00:19,  1.80s/it][A
 60%|██████    | 15/25 [00:24<00:18,  1.81s/it][A
 64%|██████▍   | 16/25 [00:25<00:14,  1.62s/it][A
 68%|██████▊   | 17/25 [00:26<00:11,  1.41s/it][A
 72%|███████▏  | 18/25 [00:28<00:10,  1.49s/it][A
 76%|███████▌  | 19/25 [00:30<00:09,  1.62s/it][A
 80%|████████  | 20/25 [00:32<00:07,  1.60s/it][A
 84%|████████▍ | 21/25 [00:33<00:06,  1.56s/it][A
 88%|████████▊ | 22/25 [00:35<00:04,  1.64s/it][A
 92%|█████████▏| 23/25 [00:37<00:03,  1.71s/it][A
 96%|█████████▌| 24/25 [00:39<00:01,  1.78s/it][A
100%|██████████| 25/25 [00:41<00:00,  1.82s/it][A                                             
                                               [A{'eval_loss': 2.4317429065704346, 'eval_runtime': 43.0321, 'eval_samples_per_second': 4.648, 'eval_steps_per_second': 0.581, 'epoch': 0.64}
 25%|██▌       | 1/4 [02:09<04:20, 86.94s/it]
100%|██████████| 25/25 [00:41<00:00,  1.82s/it][A
                                               [A/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 50%|█████     | 2/4 [03:38<03:46, 113.28s/it]
  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:01<00:19,  1.15it/s][A
 12%|█▏        | 3/25 [00:03<00:28,  1.29s/it][A
 16%|█▌        | 4/25 [00:04<00:27,  1.29s/it][A
 20%|██        | 5/25 [00:06<00:25,  1.25s/it][A
 24%|██▍       | 6/25 [00:07<00:27,  1.42s/it][A
 28%|██▊       | 7/25 [00:09<00:28,  1.59s/it][A
 32%|███▏      | 8/25 [00:11<00:28,  1.70s/it][A
 36%|███▌      | 9/25 [00:13<00:28,  1.77s/it][A
 40%|████      | 10/25 [00:15<00:27,  1.82s/it][A
 44%|████▍     | 11/25 [00:17<00:26,  1.86s/it][A
 48%|████▊     | 12/25 [00:19<00:24,  1.88s/it][A
 52%|█████▏    | 13/25 [00:21<00:22,  1.90s/it][A
 56%|█████▌    | 14/25 [00:22<00:19,  1.80s/it][A
 60%|██████    | 15/25 [00:24<00:18,  1.81s/it][A
 64%|██████▍   | 16/25 [00:26<00:14,  1.62s/it][A
 68%|██████▊   | 17/25 [00:26<00:11,  1.41s/it][A
 72%|███████▏  | 18/25 [00:28<00:10,  1.49s/it][A
 76%|███████▌  | 19/25 [00:30<00:09,  1.63s/it][A
 80%|████████  | 20/25 [00:32<00:08,  1.60s/it][A
 84%|████████▍ | 21/25 [00:33<00:06,  1.56s/it][A
 88%|████████▊ | 22/25 [00:35<00:04,  1.64s/it][A
 92%|█████████▏| 23/25 [00:37<00:03,  1.71s/it][A
 96%|█████████▌| 24/25 [00:39<00:01,  1.78s/it][A
100%|██████████| 25/25 [00:41<00:00,  1.83s/it][A                                              
                                               [A{'eval_loss': 2.4135560989379883, 'eval_runtime': 43.0622, 'eval_samples_per_second': 4.644, 'eval_steps_per_second': 0.581, 'epoch': 1.28}
 50%|█████     | 2/4 [04:21<03:46, 113.28s/it]
100%|██████████| 25/25 [00:41<00:00,  1.83s/it][A
                                               [A 75%|███████▌  | 3/4 [05:51<02:02, 122.28s/it]
  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:01<00:19,  1.15it/s][A
 12%|█▏        | 3/25 [00:03<00:28,  1.29s/it][A
 16%|█▌        | 4/25 [00:04<00:27,  1.29s/it][A
 20%|██        | 5/25 [00:06<00:25,  1.25s/it][A
 24%|██▍       | 6/25 [00:07<00:27,  1.42s/it][A
 28%|██▊       | 7/25 [00:09<00:28,  1.59s/it][A
 32%|███▏      | 8/25 [00:11<00:28,  1.70s/it][A
 36%|███▌      | 9/25 [00:13<00:28,  1.77s/it][A
 40%|████      | 10/25 [00:15<00:27,  1.82s/it][A
 44%|████▍     | 11/25 [00:17<00:26,  1.86s/it][A
 48%|████▊     | 12/25 [00:19<00:24,  1.88s/it][A
 52%|█████▏    | 13/25 [00:21<00:22,  1.90s/it][A
 56%|█████▌    | 14/25 [00:22<00:19,  1.80s/it][A
 60%|██████    | 15/25 [00:24<00:18,  1.81s/it][A
 64%|██████▍   | 16/25 [00:25<00:14,  1.62s/it][A
 68%|██████▊   | 17/25 [00:26<00:11,  1.41s/it][A
 72%|███████▏  | 18/25 [00:28<00:10,  1.49s/it][A
 76%|███████▌  | 19/25 [00:30<00:09,  1.63s/it][A
 80%|████████  | 20/25 [00:32<00:08,  1.60s/it][A
 84%|████████▍ | 21/25 [00:33<00:06,  1.56s/it][A
 88%|████████▊ | 22/25 [00:35<00:04,  1.64s/it][A
 92%|█████████▏| 23/25 [00:37<00:03,  1.71s/it][A
 96%|█████████▌| 24/25 [00:39<00:01,  1.78s/it][A
100%|██████████| 25/25 [00:41<00:00,  1.82s/it][A                                              
                                               [A{'eval_loss': 2.3529365062713623, 'eval_runtime': 43.054, 'eval_samples_per_second': 4.645, 'eval_steps_per_second': 0.581, 'epoch': 1.92}
 75%|███████▌  | 3/4 [06:34<02:02, 122.28s/it]
100%|██████████| 25/25 [00:41<00:00,  1.82s/it][A
                                               [A/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
100%|██████████| 4/4 [08:02<00:00, 125.60s/it]
  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:01<00:19,  1.15it/s][A
 12%|█▏        | 3/25 [00:03<00:28,  1.29s/it][A
 16%|█▌        | 4/25 [00:04<00:27,  1.29s/it][A
 20%|██        | 5/25 [00:06<00:25,  1.25s/it][A
 24%|██▍       | 6/25 [00:07<00:27,  1.42s/it][A
 28%|██▊       | 7/25 [00:09<00:28,  1.59s/it][A
 32%|███▏      | 8/25 [00:11<00:28,  1.70s/it][A
 36%|███▌      | 9/25 [00:13<00:28,  1.77s/it][A
 40%|████      | 10/25 [00:15<00:27,  1.82s/it][A
 44%|████▍     | 11/25 [00:17<00:26,  1.86s/it][A
 48%|████▊     | 12/25 [00:19<00:24,  1.88s/it][A
 52%|█████▏    | 13/25 [00:21<00:22,  1.90s/it][A
 56%|█████▌    | 14/25 [00:22<00:19,  1.80s/it][A
 60%|██████    | 15/25 [00:24<00:18,  1.81s/it][A
 64%|██████▍   | 16/25 [00:26<00:14,  1.62s/it][A
 68%|██████▊   | 17/25 [00:26<00:11,  1.41s/it][A
 72%|███████▏  | 18/25 [00:28<00:10,  1.49s/it][A
 76%|███████▌  | 19/25 [00:30<00:09,  1.63s/it][A
 80%|████████  | 20/25 [00:32<00:08,  1.60s/it][A
 84%|████████▍ | 21/25 [00:33<00:06,  1.56s/it][A
 88%|████████▊ | 22/25 [00:35<00:04,  1.64s/it][A
 92%|█████████▏| 23/25 [00:37<00:03,  1.71s/it][A
 96%|█████████▌| 24/25 [00:39<00:01,  1.78s/it][A
100%|██████████| 25/25 [00:41<00:00,  1.82s/it][A                                              
                                               [A{'eval_loss': 2.226984977722168, 'eval_runtime': 43.0577, 'eval_samples_per_second': 4.645, 'eval_steps_per_second': 0.581, 'epoch': 2.56}
100%|██████████| 4/4 [08:45<00:00, 125.60s/it]
100%|██████████| 25/25 [00:41<00:00,  1.82s/it][A
                                               [A                                              {'train_runtime': 525.6366, 'train_samples_per_second': 1.522, 'train_steps_per_second': 0.008, 'train_loss': 2.367304801940918, 'epoch': 2.56}
100%|██████████| 4/4 [08:45<00:00, 125.60s/it]100%|██████████| 4/4 [08:45<00:00, 131.41s/it]
trainer.state.log_history:  [{'eval_loss': 2.4317429065704346, 'eval_runtime': 43.0321, 'eval_samples_per_second': 4.648, 'eval_steps_per_second': 0.581, 'epoch': 0.64, 'step': 1}, {'eval_loss': 2.4135560989379883, 'eval_runtime': 43.0622, 'eval_samples_per_second': 4.644, 'eval_steps_per_second': 0.581, 'epoch': 1.28, 'step': 2}, {'eval_loss': 2.3529365062713623, 'eval_runtime': 43.054, 'eval_samples_per_second': 4.645, 'eval_steps_per_second': 0.581, 'epoch': 1.92, 'step': 3}, {'eval_loss': 2.226984977722168, 'eval_runtime': 43.0577, 'eval_samples_per_second': 4.645, 'eval_steps_per_second': 0.581, 'epoch': 2.56, 'step': 4}, {'train_runtime': 525.6366, 'train_samples_per_second': 1.522, 'train_steps_per_second': 0.008, 'total_flos': 8709467838382080.0, 'train_loss': 2.367304801940918, 'epoch': 2.56, 'step': 4}]
train_results:  TrainOutput(global_step=4, training_loss=2.367304801940918, metrics={'train_runtime': 525.6366, 'train_samples_per_second': 1.522, 'train_steps_per_second': 0.008, 'train_loss': 2.367304801940918, 'epoch': 2.56})
train loss: 2.367304801940918
Traceback (most recent call last):
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 194, in <module>
    plot_loss(trainer.state.log_history, f'Output_files/loss_plot_lr_{lr_scientific}_ep_{training_arguments.num_train_epochs}_ba_{training_arguments.per_device_train_batch_size}.png')
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 111, in plot_loss
    plt.plot(steps, eval_loss, label='Evaluation Loss', marker='o', color=colors[1])
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/pyplot.py", line 3590, in plot
    return gca().plot(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (0,) and (4,)
batch: 16
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.55s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.28s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.92s/it]
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2277.18 examples/s]
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2204.01 examples/s]
  0%|          | 0/4 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 25%|██▌       | 1/4 [02:25<07:16, 145.45s/it]
  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:03<00:20,  1.87s/it][A
 23%|██▎       | 3/13 [00:07<00:26,  2.63s/it][A
 31%|███       | 4/13 [00:11<00:27,  3.04s/it][A
 38%|███▊      | 5/13 [00:14<00:26,  3.27s/it][A
 46%|████▌     | 6/13 [00:18<00:23,  3.42s/it][A
 54%|█████▍    | 7/13 [00:22<00:21,  3.52s/it][A
 62%|██████▏   | 8/13 [00:26<00:17,  3.58s/it][A
 69%|██████▉   | 9/13 [00:29<00:14,  3.61s/it][A
 77%|███████▋  | 10/13 [00:33<00:10,  3.64s/it][A
 85%|████████▍ | 11/13 [00:37<00:07,  3.66s/it][A
 92%|█████████▏| 12/13 [00:40<00:03,  3.68s/it][A
100%|██████████| 13/13 [00:43<00:00,  3.28s/it][A                                              
                                               [A{'eval_loss': 2.3840248584747314, 'eval_runtime': 46.5021, 'eval_samples_per_second': 4.301, 'eval_steps_per_second': 0.28, 'epoch': 1.0}
 25%|██▌       | 1/4 [03:11<07:16, 145.45s/it]
100%|██████████| 13/13 [00:43<00:00,  3.28s/it][A
                                               [A/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 50%|█████     | 2/4 [03:48<03:38, 109.03s/it]
  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:03<00:20,  1.86s/it][A
 23%|██▎       | 3/13 [00:07<00:26,  2.63s/it][A
 31%|███       | 4/13 [00:11<00:27,  3.04s/it][A
 38%|███▊      | 5/13 [00:14<00:26,  3.28s/it][A
 46%|████▌     | 6/13 [00:18<00:23,  3.42s/it][A
 54%|█████▍    | 7/13 [00:22<00:21,  3.52s/it][A
 62%|██████▏   | 8/13 [00:26<00:17,  3.58s/it][A
 69%|██████▉   | 9/13 [00:29<00:14,  3.61s/it][A
 77%|███████▋  | 10/13 [00:33<00:10,  3.64s/it][A
 85%|████████▍ | 11/13 [00:37<00:07,  3.66s/it][A
 92%|█████████▏| 12/13 [00:40<00:03,  3.68s/it][A
100%|██████████| 13/13 [00:43<00:00,  3.28s/it][A                                              
                                               [A{'eval_loss': 2.3712449073791504, 'eval_runtime': 46.5033, 'eval_samples_per_second': 4.301, 'eval_steps_per_second': 0.28, 'epoch': 1.23}
 50%|█████     | 2/4 [04:35<03:38, 109.03s/it]
100%|██████████| 13/13 [00:43<00:00,  3.28s/it][A
                                               [A 75%|███████▌  | 3/4 [06:22<02:09, 129.18s/it]
  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:03<00:20,  1.86s/it][A
 23%|██▎       | 3/13 [00:07<00:26,  2.63s/it][A
 31%|███       | 4/13 [00:11<00:27,  3.04s/it][A
 38%|███▊      | 5/13 [00:14<00:26,  3.28s/it][A
 46%|████▌     | 6/13 [00:18<00:23,  3.42s/it][A
 54%|█████▍    | 7/13 [00:22<00:21,  3.52s/it][A
 62%|██████▏   | 8/13 [00:26<00:17,  3.58s/it][A
 69%|██████▉   | 9/13 [00:29<00:14,  3.61s/it][A
 77%|███████▋  | 10/13 [00:33<00:10,  3.63s/it][A
 85%|████████▍ | 11/13 [00:37<00:07,  3.66s/it][A
 92%|█████████▏| 12/13 [00:40<00:03,  3.68s/it][A
100%|██████████| 13/13 [00:43<00:00,  3.28s/it][A                                              
                                               [A{'eval_loss': 2.3190865516662598, 'eval_runtime': 46.4821, 'eval_samples_per_second': 4.303, 'eval_steps_per_second': 0.28, 'epoch': 2.0}
 75%|███████▌  | 3/4 [07:08<02:09, 129.18s/it]
100%|██████████| 13/13 [00:43<00:00,  3.28s/it][A
                                               [A/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
100%|██████████| 4/4 [08:23<00:00, 126.02s/it]
  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:03<00:20,  1.86s/it][A
 23%|██▎       | 3/13 [00:07<00:26,  2.63s/it][A
 31%|███       | 4/13 [00:11<00:27,  3.04s/it][A
 38%|███▊      | 5/13 [00:14<00:26,  3.27s/it][A
 46%|████▌     | 6/13 [00:18<00:23,  3.42s/it][A
 54%|█████▍    | 7/13 [00:22<00:21,  3.52s/it][A
 62%|██████▏   | 8/13 [00:26<00:17,  3.58s/it][A
 69%|██████▉   | 9/13 [00:29<00:14,  3.60s/it][A
 77%|███████▋  | 10/13 [00:33<00:10,  3.63s/it][A
 85%|████████▍ | 11/13 [00:37<00:07,  3.66s/it][A
 92%|█████████▏| 12/13 [00:40<00:03,  3.68s/it][A
100%|██████████| 13/13 [00:43<00:00,  3.28s/it][A                                              
                                               [A{'eval_loss': 2.2026777267456055, 'eval_runtime': 46.453, 'eval_samples_per_second': 4.305, 'eval_steps_per_second': 0.28, 'epoch': 2.46}
100%|██████████| 4/4 [09:09<00:00, 126.02s/it]
100%|██████████| 13/13 [00:43<00:00,  3.28s/it][A
                                               [A                                              {'train_runtime': 549.9977, 'train_samples_per_second': 1.455, 'train_steps_per_second': 0.007, 'train_loss': 1.173500418663025, 'epoch': 2.46}
100%|██████████| 4/4 [09:09<00:00, 126.02s/it]100%|██████████| 4/4 [09:09<00:00, 137.50s/it]
trainer.state.log_history:  [{'eval_loss': 2.3840248584747314, 'eval_runtime': 46.5021, 'eval_samples_per_second': 4.301, 'eval_steps_per_second': 0.28, 'epoch': 1.0, 'step': 1}, {'eval_loss': 2.3712449073791504, 'eval_runtime': 46.5033, 'eval_samples_per_second': 4.301, 'eval_steps_per_second': 0.28, 'epoch': 1.23, 'step': 2}, {'eval_loss': 2.3190865516662598, 'eval_runtime': 46.4821, 'eval_samples_per_second': 4.303, 'eval_steps_per_second': 0.28, 'epoch': 2.0, 'step': 3}, {'eval_loss': 2.2026777267456055, 'eval_runtime': 46.453, 'eval_samples_per_second': 4.305, 'eval_steps_per_second': 0.28, 'epoch': 2.46, 'step': 4}, {'train_runtime': 549.9977, 'train_samples_per_second': 1.455, 'train_steps_per_second': 0.007, 'total_flos': 9383060921794560.0, 'train_loss': 1.173500418663025, 'epoch': 2.46, 'step': 4}]
train_results:  TrainOutput(global_step=4, training_loss=1.173500418663025, metrics={'train_runtime': 549.9977, 'train_samples_per_second': 1.455, 'train_steps_per_second': 0.007, 'train_loss': 1.173500418663025, 'epoch': 2.46})
train loss: 1.173500418663025
Traceback (most recent call last):
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 194, in <module>
    plot_loss(trainer.state.log_history, f'Output_files/loss_plot_lr_{lr_scientific}_ep_{training_arguments.num_train_epochs}_ba_{training_arguments.per_device_train_batch_size}.png')
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 111, in plot_loss
    plt.plot(steps, eval_loss, label='Evaluation Loss', marker='o', color=colors[1])
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/pyplot.py", line 3590, in plot
    return gca().plot(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (0,) and (4,)
batch: 32
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.23s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.69s/it]
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2433.28 examples/s]
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2292.40 examples/s]
  0%|          | 0/4 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 25%|██▌       | 1/4 [02:22<07:07, 142.43s/it]
  0%|          | 0/7 [00:00<?, ?it/s][A
 29%|██▊       | 2/7 [00:07<00:18,  3.62s/it][A
 43%|████▎     | 3/7 [00:14<00:20,  5.13s/it][A
 57%|█████▋    | 4/7 [00:21<00:17,  5.91s/it][A
 71%|███████▏  | 5/7 [00:28<00:12,  6.37s/it][A
 86%|████████▌ | 6/7 [00:36<00:06,  6.65s/it][A
100%|██████████| 7/7 [00:39<00:00,  5.56s/it][A                                              
                                             [A{'eval_loss': 2.379411220550537, 'eval_runtime': 45.3319, 'eval_samples_per_second': 4.412, 'eval_steps_per_second': 0.154, 'epoch': 1.0}
 25%|██▌       | 1/4 [03:07<07:07, 142.43s/it]
100%|██████████| 7/7 [00:39<00:00,  5.56s/it][A
                                             [A/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 50%|█████     | 2/4 [05:34<05:43, 171.55s/it]
  0%|          | 0/7 [00:00<?, ?it/s][A
 29%|██▊       | 2/7 [00:07<00:18,  3.62s/it][A
 43%|████▎     | 3/7 [00:14<00:20,  5.12s/it][A
 57%|█████▋    | 4/7 [00:21<00:17,  5.91s/it][A
 71%|███████▏  | 5/7 [00:28<00:12,  6.37s/it][A
 86%|████████▌ | 6/7 [00:36<00:06,  6.66s/it][A
100%|██████████| 7/7 [00:39<00:00,  5.56s/it][A                                              
                                             [A{'eval_loss': 2.364027261734009, 'eval_runtime': 45.3302, 'eval_samples_per_second': 4.412, 'eval_steps_per_second': 0.154, 'epoch': 2.0}
 50%|█████     | 2/4 [06:19<05:43, 171.55s/it]
100%|██████████| 7/7 [00:39<00:00,  5.56s/it][A
                                             [A/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 75%|███████▌  | 3/4 [07:05<02:14, 134.69s/it]
  0%|          | 0/7 [00:00<?, ?it/s][A
 29%|██▊       | 2/7 [00:07<00:18,  3.61s/it][A
 43%|████▎     | 3/7 [00:14<00:20,  5.12s/it][A
 57%|█████▋    | 4/7 [00:21<00:17,  5.91s/it][A
 71%|███████▏  | 5/7 [00:28<00:12,  6.37s/it][A
 86%|████████▌ | 6/7 [00:36<00:06,  6.66s/it][A
100%|██████████| 7/7 [00:39<00:00,  5.56s/it][A                                              
                                             [A{'eval_loss': 2.3130481243133545, 'eval_runtime': 45.3436, 'eval_samples_per_second': 4.411, 'eval_steps_per_second': 0.154, 'epoch': 2.29}
 75%|███████▌  | 3/4 [07:50<02:14, 134.69s/it]
100%|██████████| 7/7 [00:39<00:00,  5.56s/it][A
                                             [A100%|██████████| 4/4 [09:30<00:00, 139.06s/it]
  0%|          | 0/7 [00:00<?, ?it/s][A
 29%|██▊       | 2/7 [00:07<00:18,  3.63s/it][A
 43%|████▎     | 3/7 [00:14<00:20,  5.14s/it][A
 57%|█████▋    | 4/7 [00:21<00:17,  5.92s/it][A
 71%|███████▏  | 5/7 [00:29<00:12,  6.39s/it][A
 86%|████████▌ | 6/7 [00:36<00:06,  6.67s/it][A
100%|██████████| 7/7 [00:39<00:00,  5.57s/it][A                                              
                                             [A{'eval_loss': 2.2010316848754883, 'eval_runtime': 45.4228, 'eval_samples_per_second': 4.403, 'eval_steps_per_second': 0.154, 'epoch': 3.0}
100%|██████████| 4/4 [10:16<00:00, 139.06s/it]
100%|██████████| 7/7 [00:39<00:00,  5.57s/it][A
                                             [A                                              {'train_runtime': 616.6134, 'train_samples_per_second': 1.297, 'train_steps_per_second': 0.006, 'train_loss': 0.7659401297569275, 'epoch': 3.0}
100%|██████████| 4/4 [10:16<00:00, 139.06s/it]100%|██████████| 4/4 [10:16<00:00, 154.15s/it]
trainer.state.log_history:  [{'eval_loss': 2.379411220550537, 'eval_runtime': 45.3319, 'eval_samples_per_second': 4.412, 'eval_steps_per_second': 0.154, 'epoch': 1.0, 'step': 1}, {'eval_loss': 2.364027261734009, 'eval_runtime': 45.3302, 'eval_samples_per_second': 4.412, 'eval_steps_per_second': 0.154, 'epoch': 2.0, 'step': 2}, {'eval_loss': 2.3130481243133545, 'eval_runtime': 45.3436, 'eval_samples_per_second': 4.411, 'eval_steps_per_second': 0.154, 'epoch': 2.29, 'step': 3}, {'eval_loss': 2.2010316848754883, 'eval_runtime': 45.4228, 'eval_samples_per_second': 4.403, 'eval_steps_per_second': 0.154, 'epoch': 3.0, 'step': 4}, {'train_runtime': 616.6134, 'train_samples_per_second': 1.297, 'train_steps_per_second': 0.006, 'total_flos': 1.165413021696e+16, 'train_loss': 0.7659401297569275, 'epoch': 3.0, 'step': 4}]
train_results:  TrainOutput(global_step=4, training_loss=0.7659401297569275, metrics={'train_runtime': 616.6134, 'train_samples_per_second': 1.297, 'train_steps_per_second': 0.006, 'train_loss': 0.7659401297569275, 'epoch': 3.0})
train loss: 0.7659401297569275
Traceback (most recent call last):
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 194, in <module>
    plot_loss(trainer.state.log_history, f'Output_files/loss_plot_lr_{lr_scientific}_ep_{training_arguments.num_train_epochs}_ba_{training_arguments.per_device_train_batch_size}.png')
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 111, in plot_loss
    plt.plot(steps, eval_loss, label='Evaluation Loss', marker='o', color=colors[1])
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/pyplot.py", line 3590, in plot
    return gca().plot(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (0,) and (4,)
batch: 64
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.54s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.72s/it]
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2426.73 examples/s]
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|██████████| 200/200 [00:00<00:00, 2257.10 examples/s]
  0%|          | 0/4 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Traceback (most recent call last):
  File "/gpfs/bwfor/home/tu/tu_tu/tu_zxojp43/master_thesis/SFT/training.py", line 189, in <module>
    train_result = trainer.train()
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/transformers/trainer.py", line 1809, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/transformers/trainer.py", line 2654, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/transformers/trainer.py", line 2679, in compute_loss
    outputs = model(**inputs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/accelerate/utils/operations.py", line 581, in forward
    return model_forward(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/accelerate/utils/operations.py", line 569, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 16, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/peft/peft_model.py", line 922, in forward
    return self.base_model(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 806, in forward
    outputs = self.model(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 685, in forward
    layer_outputs = torch.utils.checkpoint.checkpoint(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/_compile.py", line 24, in inner
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 489, in _fn
    return fn(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 482, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/autograd/function.py", line 553, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 261, in forward
    outputs = run_function(*args)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 681, in custom_forward
    return module(*inputs, output_attentions, None)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 408, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/accelerate/hooks.py", line 165, in new_forward
    output = old_forward(*args, **kwargs)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 346, in forward
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 1860, in softmax
    ret = input.softmax(dim, dtype=dtype)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.50 GiB. GPU 0 has a total capacity of 44.35 GiB of which 1.75 GiB is free. Including non-PyTorch memory, this process has 42.59 GiB memory in use. Of the allocated memory 37.50 GiB is allocated by PyTorch, and 4.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 0/4 [00:15<?, ?it/s]
