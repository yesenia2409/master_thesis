Running simulation
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:03<00:18,  3.60s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:07<00:14,  3.55s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:10<00:10,  3.65s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:14<00:07,  3.62s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:18<00:03,  3.66s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:19<00:00,  2.76s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:19<00:00,  3.20s/it]
WARNING:root:A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from '../SFT/merged_model/SFT_for_expert_alignment/', and no v_head weight is found. This IS expected if you are not resuming PPO training.
Done loading Policy Model and Tokenizer!
/home/tu/tu_tu/tu_zxojp43/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Done loading Reward Model and Tokenizer!
WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
WARNING:root:`peft_config` argument ignored since a peft config file was found in Policy_Model/
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:03<00:17,  3.57s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:07<00:14,  3.58s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:11<00:11,  3.91s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:14<00:07,  3.76s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:18<00:03,  3.76s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:19<00:00,  2.82s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:19<00:00,  3.29s/it]
Done loading Policy Model and Tokenizer!
["<s> How old is the earth?\n\nThe Earth is estimated to be 4.54 billion years old. This estimate is based on a variety of methods, including radiometric dating of rocks and meteorites, and the study of the Earth's magnetic field and the rate of cooling of the Earth's core.\n\nThe most widely accepted age for the Earth is based on the radioactive decay of uranium and lead isotopes in rocks and meteorites. This method has been used to date rocks and meteorites with an age of 4.54 billion years, with an error margin of about 100 million years.\n\nThe Earth's magnetic field is also thought to be about 4.5 billion years old, based on the study of rocks and meteorites. The Earth's core is thought to have formed about 4.5 billion years ago, and the magnetic field is thought to have developed about 4.4 billion years ago.\n\nThe rate of cooling of the Earth's core is also thought to be about 4.5 billion years old, based on the study of the Earth's magnetic field and the rate of cooling of the Earth's core.\n\nOverall, the"]
